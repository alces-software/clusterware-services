#!/bin/bash -e
#==============================================================================
# Copyright (C) 2017 Stephen F. Norledge and Alces Software Ltd.
#
# This file/package is part of Alces Clusterware.
#
# Alces Clusterware is free software: you can redistribute it and/or
# modify it under the terms of the GNU Affero General Public License
# as published by the Free Software Foundation, either version 3 of
# the License, or (at your option) any later version.
#
# Alces Clusterware is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this package.  If not, see <http://www.gnu.org/licenses/>.
#
# For more information on the Alces Clusterware, please visit:
# https://github.com/alces-software/clusterware
#==============================================================================
if [ "$cw_DEBUG" ]; then
    set -x
fi

setup() {
    local a xdg_config
    IFS=: read -a xdg_config <<< "${XDG_CONFIG_HOME:-$HOME/.config}:${XDG_CONFIG_DIRS:-/etc/xdg}"
    for a in "${xdg_config[@]}"; do
        if [ -e "${a}"/clusterware/config.vars.sh ]; then
            source "${a}"/clusterware/config.vars.sh
            break
        fi
    done
    if [ -z "${cw_ROOT}" ]; then
        echo "$0: unable to locate clusterware configuration"
        exit 1
    fi
    kernel_load
}

join_by() {
  local d=$1
  shift
  echo -n "$1"
  shift
  printf "%s" "${@/#/$d}"
}

main() {
    local image work_dir input_dir output_dir job_uuid launcher entrypoint interactive
    local m mount_src mount_dest mounts
    image="$1"
    work_dir="$2"
    input_dir="${3}"
    output_dir="${4}"

    shift 4

    if [ -z "$work_dir" ]; then
        action_die "please specify work directory."
    fi
    if [ -z "$input_dir" ]; then
        action_die "please specify input directory."
    fi
    if [ -z "$output_dir" ]; then
        action_die "please specify output directory."
    fi

    job_uuid=$(uuid)

    mounts=("$work_dir:$_INTERNAL_ROOT/work" "$input_dir:$_INTERNAL_ROOT/input" "$output_dir:$_INTERNAL_ROOT/output")

    while [[ "$1" == "--mount" ]]; do
      if [ -z "$2" ]; then
        action_die "--mount option requires an argument."
      fi

      mount_src=${2%:*}
      mount_dest=${2#*:}

      if [[ "$mount_src" == "$2" ]]; then
        action_die "Volume mounts should be specified as /path/on/host:/path/in/container."
      fi

      for m in "work" "input" "output"; do
        if [[ "$mount_dest" == "${_INTERNAL_ROOT}/${m}" || "$mount_dest" == "${_INTERNAL_ROOT}/${m}/"* ]]; then
          action_die "Cannot override mount point ${_INTERNAL_ROOT}/${m}."
        fi
      done

      mounts+=("${mount_src}:${mount_dest}")
      shift 2
    done

    run_args=("${@}")

    if [ "${run_args[0]}" == "--interactive" ]; then
        interactive="-it"
        if [ "${run_args[1]}" ]; then
            launcher=(${run_args[@]:1})
        else
            launcher=(/bin/bash)
        fi
    else
        entrypoint="$(docker inspect ${image} | ${_JQ} -Mrc '.[].Config.Entrypoint | join(" ")')"
        if [ "${run_args[0]}" == "--script" ]; then
            launcher=(${entrypoint} $_INTERNAL_ROOT/work/workload.sh "${run_args[@]:1}")
        elif [ "${run_args[0]}" == "--command" ]; then
            launcher=("${run_args[@]:1}")
        else
            launcher=(${entrypoint} "${run_args[@]}")
        fi
    fi

    cat <<EOF >$work_dir/Dockerfile
FROM ${image}

RUN useradd -m -u $SUDO_UID $SUDO_USER

EOF

   if [[ ! -z "$use_mpi" ]]; then
     # set up SSH key for sshd in container so that all copies of the temp image
     # can log into each other
     mkdir -p $work_dir/ssh
     ssh-keygen -t rsa -f $work_dir/ssh/id_rsa -N ''
     cp $work_dir/ssh/id_rsa.pub $work_dir/ssh/authorized_keys
     cat <<EOF > $work_dir/ssh/config
 Host *
   IdentityFile %d/.ssh/id_rsa
   StrictHostKeyChecking  no
EOF
     chmod 600 $work_dir/ssh/
     cat <<EOF >>$work_dir/Dockerfile
     COPY ssh /home/$SUDO_USER/.ssh
     RUN chown -R $_UID:$_GID /home/$SUDO_USER/.ssh
EOF
   fi

    docker build -t $job_uuid $work_dir >> $work_dir/docker.log

    if [[ ! -z "$use_mpi" ]]; then
      # This step currently gives some scary-looking errors that aren't actually errors
      docker service create --network gridware-mpi --replicas 2 --name ${job_uuid}-service ${job_uuid} --mpi >> $work_dir/docker.log
      # Now wait until all replicas have been created
      while true; do
        replicas=$(docker service ls --filter name=${job_uuid}-service | tail -n -1 | cut -d' ' -f7)
        ready=${replicas%/*}
        total=${replicas#*/}
        if [[ "$ready" == "$total" ]]; then break; fi
        sleep 5
      done

      # Assemble a hosts file
       containers=$(docker service ps --no-trunc -f "desired-state=running" ${job_uuid}-service | tail -n +2 | awk '{print $2"."$1}')
       for container in $containers; do
         ip=$(docker inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}""{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}" $container)
         echo "$container $ip" >> $work_dir/hosts
       done

    fi

    set +e
    docker run $interactive --rm=true \
           -v $(join_by " -v " "${mounts[@]}") \
           --env "WORK_DIR=$_INTERNAL_ROOT/work" \
           --env "INPUT_DIR=$_INTERNAL_ROOT/input" \
           --env "OUTPUT_DIR=$_INTERNAL_ROOT/output" \
           --user "$_UID:$_GID" \
           $use_mpi \
           $job_uuid \
           "${launcher[@]}"

    if [[ ! -z "$use_mpi" ]]; then
      docker service rm ${job_uuid}-service >> $work_dir/docker.log
    fi
    docker rmi $job_uuid >> $work_dir/docker.log
}

setup
require action
require process

if ! process_reexec_sg docker --plain "$@"; then
   action_die "unable to find group: docker"
fi

_INTERNAL_ROOT=/job
_UID=${SUDO_UID:-$UID}
_GID=$(id -g $SUDO_USER)
_JQ="${cw_ROOT}"/opt/jq/bin/jq

main "$@"
